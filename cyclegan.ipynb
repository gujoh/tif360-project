{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from  matplotlib import pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "from utils import get_data, show_batch\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for storing things such as learning rate, image size...\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.lr = 2e-4\n",
    "        self.epochs = 200\n",
    "        self.b1 = 0.5\n",
    "        self.b2 = 0.999\n",
    "        self.latent_dim = 100\n",
    "        self.img_size = 64\n",
    "        self.pixels = int(self.img_size ** 2)\n",
    "        self.channels = 3\n",
    "        self.img_tuple = (self.channels, self.img_size, self.img_size)\n",
    "        self.batch_size = 32\n",
    "        self.g_fmap_size = 64 \n",
    "        self.d_fmap_size = 64\n",
    "        self.d_loss_threshold = 0.5\n",
    "        self.n_res_blocks = 9\n",
    "        self.decay_epoch = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the images.\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "args = Args()\n",
    "transform = transforms.Compose([transforms.Resize(args.img_size),\n",
    "                                transforms.CenterCrop(args.img_size),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "paintings, photos, painting_loader, photo_loader = get_data(transform=transform, batch_size=args.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Generator. \n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super().__init__()\n",
    "        self.pad1 = nn.ReflectionPad1d(1)\n",
    "        self.pad2 = nn.ReflectionPad1d(in_features)\n",
    "        self.conv1 = nn.Conv2d(in_features, in_features, 3)\n",
    "        self.conv2 = nn.Conv2d(in_features, in_features, 3)\n",
    "        self.norm1 = nn.InstanceNorm2d(in_features)\n",
    "        self.norm2 = nn.InstanceNorm2d(in_features)\n",
    "    \n",
    "    def block(self, x):\n",
    "        x = self.pad1(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.norm1(x)\n",
    "        x = x.relu()\n",
    "        x = self.pad2(x)\n",
    "        x = self.conv2(x)\n",
    "        return self.norm2(x)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)\n",
    "    \n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.out_features = 64\n",
    "        self.in_features = self.out_features\n",
    "        self.__compile_model()\n",
    "        \n",
    "    # First convolutional block. \n",
    "    def __conv1(self):\n",
    "        self.model += [\n",
    "            nn.ReflectionPad2d(args.channels),\n",
    "            nn.Conv2d(args.channels, self.out_features, 7),\n",
    "            nn.InstanceNorm2d(self.out_features),\n",
    "            nn.ReLU(inplace=True)\n",
    "            ]\n",
    "                       \n",
    "    # Downsampling\n",
    "    def __downsample(self):\n",
    "        for _ in range(2):\n",
    "            self.out_features *= 2  \n",
    "            self.model += [\n",
    "                nn.Conv2d(self.in_features, self.out_features, 3, stride=2, padding=1),\n",
    "                nn.InstanceNorm2d(self.out_features),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ]\n",
    "        self.in_features = self.out_features\n",
    "\n",
    "    def __residual_blocks(self):\n",
    "        for _ in range(args.n_res_blocks):\n",
    "            self.model += [ResidualBlock(self.out_features)]\n",
    "\n",
    "    # Upsampling \n",
    "    def __upsample(self):\n",
    "        for _ in range(2):\n",
    "            self.out_features //= 2\n",
    "            self.model += [\n",
    "                nn.Upsample(scale_factor=2),\n",
    "                nn.Conv2d(self.in_features, self.out_features, 3, stride=1, padding=1),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ]\n",
    "        self.in_features = self.out_features\n",
    "\n",
    "    # Output layer\n",
    "    def __output(self):\n",
    "        self.model += [\n",
    "            nn.ReflectionPad2d(args.channels),\n",
    "            nn.Conv2d(self.out_features, args.channels, 7),\n",
    "            nn.Tanh()\n",
    "        ]\n",
    "    \n",
    "    # Compiles the model\n",
    "    def __compile_model(self):\n",
    "        self.model = []\n",
    "        self.__conv1()\n",
    "        self.__downsample()\n",
    "        self.__residual_blocks()\n",
    "        self.__upsample()\n",
    "        self.__output()\n",
    "        self.model = nn.Sequential(*self.model)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the discriminator.\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.output_shape = (1, args.img_size // 2 ** 4, args.img_size // 2 ** 4)\n",
    "        self.__compile_model()\n",
    "    \n",
    "    def __discriminator_block(self, in_filters, out_filters, normalize=True):\n",
    "        layers = [nn.Conv2d(in_filters, out_filters, 4, stride=2, padding=1)]\n",
    "        if normalize:\n",
    "            layers.append(nn.InstanceNorm2d(out_filters))\n",
    "        layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "        return layers \n",
    "\n",
    "    def __compile_model(self):\n",
    "        self.model = nn.Sequential(\n",
    "            *self.__discriminator_block(args.channels, 64,  normalize=False),\n",
    "            *self.__discriminator_block(64, 128),\n",
    "            *self.__discriminator_block(128, 256),\n",
    "            *self.__discriminator_block(256, 512),\n",
    "            nn.ZeroPad2d((1, 0, 1, 0)),\n",
    "            nn.Conv2d(512, 1, 4, padding=1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializes weights to a Gaussian distribution. \n",
    "def init_weights(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "        if hasattr(m, 'bias') and m.bias is not None:\n",
    "            nn.init.constant_(m.bias.data, 0.0)\n",
    "    elif classname.find('BatchNorm2d') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (model): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (11): ZeroPad2d((1, 0, 1, 0))\n",
       "    (12): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initalizing the networks. \n",
    "gen_ab = Generator().to(device)\n",
    "gen_ba = Generator().to(device)\n",
    "disc_a = Discriminator().to(device)\n",
    "disc_b = Discriminator().to(device)\n",
    "loss_gen = nn.MSELoss()\n",
    "loss_cycle = nn.L1Loss()\n",
    "loss_identity = nn.L1Loss()\n",
    "\n",
    "gen_ab.apply(init_weights)\n",
    "gen_ba.apply(init_weights)\n",
    "disc_a.apply(init_weights)\n",
    "disc_b.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up optimizers. \n",
    "optim_g = torch.optim.Adam(\n",
    "    itertools.chain(gen_ab.parameters(), gen_ba.parameters()), lr=args.lr, betas=(args.b1, args.b2)\n",
    "    )\n",
    "optim_d_a = torch.optim.Adam(\n",
    "    disc_a.parameters(), lr=args.lr, betas=(args.b1, args.b2)\n",
    ")\n",
    "optim_d_b = torch.optim.Adam(\n",
    "    disc_b.parameters(), lr=args.lr, betas=(args.b1, args.b2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate scheduler.\n",
    "class LambdaLR:\n",
    "    def __init__(self, n_epochs, offset, decay_start_epoch):\n",
    "        assert (n_epochs - decay_start_epoch) > 0, \"n_epochs must be larger than decay_start_epoch\"\n",
    "        self.n_epochs = n_epochs \n",
    "        self.offset = offset \n",
    "        self.decay_start_epoch = decay_start_epoch\n",
    "    \n",
    "    def step(self, epoch):\n",
    "        return 1.0 - max(0, epoch+self.offset - self.decay_start_epoch) / (self.n_epochs - self.decay_start_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler_g = torch.optim.lr_scheduler.LambdaLR(\n",
    "    optim_g,\n",
    "    lr_lambda=LambdaLR(args.epochs, 0, args.decay_epoch).step\n",
    ")\n",
    "lr_scheduler_d_a = torch.optim.lr_scheduler.LambdaLR(\n",
    "    optim_d_a,\n",
    "    lr_lambda=LambdaLR(args.epochs, 0, args.decay_epoch).step\n",
    ")\n",
    "lr_scheduler_d_b = torch.optim.lr_scheduler.LambdaLR(\n",
    "    optim_d_b,\n",
    "    lr_lambda=LambdaLR(args.epochs, 0, args.decay_epoch).step\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
