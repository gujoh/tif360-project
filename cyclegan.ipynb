{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from  matplotlib import pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "from utils import get_data, show_batch\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for storing things such as learning rate, image size...\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.lr = 2e-4\n",
    "        self.epochs = 200\n",
    "        self.b1 = 0.5\n",
    "        self.b2 = 0.999\n",
    "        self.latent_dim = 100\n",
    "        self.img_size = 64\n",
    "        self.pixels = int(self.img_size ** 2)\n",
    "        self.channels = 3\n",
    "        self.img_tuple = (self.channels, self.img_size, self.img_size)\n",
    "        self.batch_size = 32\n",
    "        self.g_fmap_size = 64 \n",
    "        self.d_fmap_size = 64\n",
    "        self.d_loss_threshold = 0.5\n",
    "        self.n_res_blocks = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the images.\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "args = Args()\n",
    "transform = transforms.Compose([transforms.Resize(args.img_size),\n",
    "                                transforms.CenterCrop(args.img_size),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "paintings, photos, painting_loader, photo_loader = get_data(transform=transform, batch_size=args.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Generator. \n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super().__init__()\n",
    "        self.pad1 = nn.ReflectionPad1d(1)\n",
    "        self.pad2 = nn.ReflectionPad1d(in_features)\n",
    "        self.conv1 = nn.Conv2d(in_features, in_features, 3)\n",
    "        self.conv2 = nn.Conv2(in_features, in_features, 3)\n",
    "        self.norm1 = nn.InstanceNorm2d(in_features)\n",
    "        self.norm2 = nn.InstanceNorm2d(in_features)\n",
    "    \n",
    "    def block(self, x):\n",
    "        x = self.pad1(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.norm1(x)\n",
    "        x = x.relu()\n",
    "        x = self.pad2(x)\n",
    "        x = self.conv2(x)\n",
    "        return self.norm2(x)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)\n",
    "    \n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, num_residual_block):\n",
    "        super().__init__()\n",
    "        self.out_features = 64\n",
    "        self.in_features = self.out_features\n",
    "        self.num_residual_blocks = num_residual_block\n",
    "        self.__compile_model()\n",
    "        \n",
    "    # First convolutional block. \n",
    "    def __conv1(self):\n",
    "        self.model += [\n",
    "            nn.ReflectionPad2(args.channels),\n",
    "            nn.Conv2d(args.channels, self.out_features, 7),\n",
    "            nn.InstanceNorm2d(self.out_features),\n",
    "            nn.ReLU(inplace=True)\n",
    "            ]\n",
    "                       \n",
    "    # Downsampling\n",
    "    def __downsample(self):\n",
    "        for _ in range(2):\n",
    "            self.out_features *= 2  \n",
    "            self.model += [\n",
    "                nn.Conv2d(self.in_features, self.out_features, 3, stride=2, padding=1),\n",
    "                nn.InstanceNorm2d(self.out_features),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ]\n",
    "        self.in_features = self.out_features\n",
    "\n",
    "    def __residual_blocks(self):\n",
    "        for _ in range(self.num_residual_blocks):\n",
    "            model += [ResidualBlock(self.out_features)]\n",
    "\n",
    "    # Upsampling \n",
    "    def __upsample(self):\n",
    "        for _ in range(2):\n",
    "            self.out_features //= 2\n",
    "            self.model += [\n",
    "                nn.Upsample(scale_factor=2),\n",
    "                nn.Conv2d(self.in_features, self.out_features, 3, stride=1, padding=1),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ]\n",
    "        self.in_features = self.out_features\n",
    "\n",
    "    # Output layer\n",
    "    def __output(self):\n",
    "        model += [\n",
    "            nn.ReflectionPad2d(args.channels),\n",
    "            nn.Conv2d(self.out_features, args.channels, 7),\n",
    "            nn.Tanh()\n",
    "        ]\n",
    "    \n",
    "    # Compiles the model\n",
    "    def __compile_model(self):\n",
    "        self.model = []\n",
    "        self.__conv1()\n",
    "        self.__downsample()\n",
    "        self.__residual_blocks()\n",
    "        self.__upsample()\n",
    "        self.__output()\n",
    "        self.model = nn.Sequential(*self.model)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the discriminator.\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.output_shape = (1, args.img_size // 2 ** 4, args.img_size // 2 ** 4)\n",
    "        self.__compile_model()\n",
    "    \n",
    "    def __discriminator_block(self, in_filters, out_filters, normalize=True):\n",
    "        layers = [nn.Conv2d(in_filters, out_filters, 4, stride=2, padding=1)]\n",
    "        if normalize:\n",
    "            layers.append(nn.InstanceNorm2d(out_filters))\n",
    "        layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "        return layers \n",
    "\n",
    "    def __compile_model(self):\n",
    "        self.model = nn.Sequential[\n",
    "            self.__discriminator_block(args.channels, 64,  normalize=False),\n",
    "            self.__discriminator_block(64, 128),\n",
    "            self.__discriminator_block(128, 256),\n",
    "            self.__discriminator_block(256, 512),\n",
    "            nn.ZeroPad2d((1, 0, 1, 0)),\n",
    "            nn.Conv2d(512, 1, 4, padding=1)\n",
    "        ]\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializes weights to a Gaussian distribution. \n",
    "def init_weights(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "        if hasattr(m, 'bias') and m.bias is not None:\n",
    "            nn.init.constant_(m.bias.data, 0.0)\n",
    "    elif classname.find('BatchNorm2d') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initalizing the networks. \n",
    "gen_ab = Generator(args.img_tuple, args.n_res_blocks).to(device)\n",
    "gen_ba = Generator(args.img_tuple, args.n_res_blocks).to(device)\n",
    "disc_a = Discriminator(args.img_tuple).to(device)\n",
    "disc_b = Discriminator(args.img_tuple).to(device)\n",
    "loss_gen = nn.MSELoss()\n",
    "loss_cycle = nn.L1Loss()\n",
    "loss_identity = nn.L1Loss()\n",
    "\n",
    "gen_ab.apply(init_weights)\n",
    "gen_ba.apply(init_weights)\n",
    "disc_a.apply(init_weights)\n",
    "disc_b.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up optimizers. \n",
    "optim_g = torch.optim.Adam(\n",
    "    itertools.chain(gen_ab.parameters(), gen_ba.parameters()), lr=args.lr, betas=(args.b1, args.b2)\n",
    "    )\n",
    "optim_d_a = torch.optim.Adam(\n",
    "    disc_a.parameters(), lr=args.lr, betas=(args.b1, args.b2)\n",
    ")\n",
    "optim_d_b = torch.optim.Adam(\n",
    "    disc_b.parameters(), lr=args.lr, betas=(args.b1, args.b2)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
