{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "from torchvision import transforms\n",
    "from  matplotlib import pyplot as plt\n",
    "from utils import CycleDataset, show_batch\n",
    "import itertools\n",
    "from tqdm.notebook import tqdm\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for storing things such as learning rate, image size...\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.lr = 2e-4\n",
    "        self.epochs = 200\n",
    "        self.b1 = 0.5\n",
    "        self.b2 = 0.999\n",
    "        self.img_size = 64\n",
    "        self.pixels = int(self.img_size ** 2)\n",
    "        self.channels = 3\n",
    "        self.img_tuple = (self.channels, self.img_size, self.img_size)\n",
    "        self.batch_size = 1\n",
    "        self.d_loss_threshold = 0.5\n",
    "        self.n_res_blocks = 9\n",
    "        self.decay_epoch = 5\n",
    "        self.start_epoch = 1\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the images.\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(int(args.img_size*1.12), Image.BICUBIC),\n",
    "    transforms.RandomCrop((args.img_size, args.img_size)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "loader = torch.utils.data.DataLoader(\n",
    "    CycleDataset(\"data/\", transform=transform, unaligned=True),\n",
    "    batch_size=args.batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    CycleDataset(\"data/\", transform=transform, unaligned=True),\n",
    "    batch_size=4,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Generator. \n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super().__init__()\n",
    "        self.pad1 = nn.ReflectionPad2d(1)\n",
    "        self.pad2 = nn.ReflectionPad2d(1)\n",
    "        self.conv1 = nn.Conv2d(in_features, in_features, 3)\n",
    "        self.conv2 = nn.Conv2d(in_features, in_features, 3)\n",
    "        self.norm1 = nn.InstanceNorm2d(in_features)\n",
    "        self.norm2 = nn.InstanceNorm2d(in_features)\n",
    "    \n",
    "    def block(self, x):\n",
    "        x = self.pad1(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.norm1(x)\n",
    "        x = x.relu()\n",
    "        x = self.pad2(x)\n",
    "        x = self.conv2(x)\n",
    "        return self.norm2(x)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)\n",
    "    \n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.out_features = 64\n",
    "        self.in_features = self.out_features\n",
    "        self.__compile_model()\n",
    "        \n",
    "    # First convolutional block. \n",
    "    def __conv1(self):\n",
    "        self.model += [\n",
    "            nn.ReflectionPad2d(args.channels),\n",
    "            nn.Conv2d(args.channels, self.out_features, 7),\n",
    "            nn.InstanceNorm2d(self.out_features),\n",
    "            nn.ReLU(inplace=True)\n",
    "        ]\n",
    "                       \n",
    "    # Downsampling\n",
    "    def __downsample(self):\n",
    "        for _ in range(2):\n",
    "            self.out_features *= 2  \n",
    "            self.model += [\n",
    "                nn.Conv2d(self.in_features, self.out_features, 3, stride=2, padding=1),\n",
    "                nn.InstanceNorm2d(self.out_features),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ]\n",
    "            self.in_features = self.out_features\n",
    "\n",
    "    def __residual_blocks(self):\n",
    "        for _ in range(args.n_res_blocks):\n",
    "            self.model += [ResidualBlock(self.out_features)]\n",
    "\n",
    "    # Upsampling \n",
    "    def __upsample(self):\n",
    "        for _ in range(2):\n",
    "            self.out_features //= 2\n",
    "            self.model += [\n",
    "                nn.Upsample(scale_factor=2),\n",
    "                nn.Conv2d(self.in_features, self.out_features, 3, stride=1, padding=1),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ]\n",
    "            self.in_features = self.out_features\n",
    "\n",
    "    # Output layer\n",
    "    def __output(self):\n",
    "        self.model += [\n",
    "            nn.ReflectionPad2d(args.channels),\n",
    "            nn.Conv2d(self.out_features, args.channels, 7),\n",
    "            nn.Tanh()\n",
    "        ]\n",
    "    \n",
    "    # Compiles the model\n",
    "    def __compile_model(self):\n",
    "        self.model = []\n",
    "        self.__conv1()\n",
    "        self.__downsample()\n",
    "        self.__residual_blocks()\n",
    "        self.__upsample()\n",
    "        self.__output()\n",
    "        self.model = nn.Sequential(*self.model)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the discriminator.\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.output_shape = (1, args.img_size // 2 ** 4, args.img_size // 2 ** 4)\n",
    "        self.__compile_model()\n",
    "    \n",
    "    def __discriminator_block(self, in_filters, out_filters, normalize=True):\n",
    "        layers = [nn.Conv2d(in_filters, out_filters, 4, stride=2, padding=1)]\n",
    "        if normalize:\n",
    "            layers.append(nn.InstanceNorm2d(out_filters))\n",
    "        layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "        return layers \n",
    "\n",
    "    def __compile_model(self):\n",
    "        self.model = nn.Sequential(\n",
    "            *self.__discriminator_block(args.channels, 64,  normalize=False),\n",
    "            *self.__discriminator_block(64, 128),\n",
    "            *self.__discriminator_block(128, 256),\n",
    "            *self.__discriminator_block(256, 512),\n",
    "            nn.ZeroPad2d((1, 0, 1, 0)),\n",
    "            nn.Conv2d(512, 1, 4, padding=1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializes weights to a Gaussian distribution. \n",
    "def init_weights(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "        if hasattr(m, 'bias') and m.bias is not None:\n",
    "            nn.init.constant_(m.bias.data, 0.0)\n",
    "    elif classname.find('BatchNorm2d') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (model): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (11): ZeroPad2d((1, 0, 1, 0))\n",
       "    (12): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initalizing the networks. \n",
    "gen_ab = Generator().to(device)\n",
    "gen_ba = Generator().to(device)\n",
    "disc_a = Discriminator().to(device)\n",
    "disc_b = Discriminator().to(device)\n",
    "loss_fn_gan = nn.MSELoss()\n",
    "loss_fn_cycle = nn.L1Loss()\n",
    "loss_fn_identity = nn.L1Loss()\n",
    "\n",
    "gen_ab.apply(init_weights)\n",
    "gen_ba.apply(init_weights)\n",
    "disc_a.apply(init_weights)\n",
    "disc_b.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up optimizers. \n",
    "optim_g = torch.optim.Adam(\n",
    "    itertools.chain(gen_ab.parameters(), gen_ba.parameters()), lr=args.lr, betas=(args.b1, args.b2)\n",
    "    )\n",
    "optim_d_a = torch.optim.Adam(\n",
    "    disc_a.parameters(), lr=args.lr, betas=(args.b1, args.b2)\n",
    ")\n",
    "optim_d_b = torch.optim.Adam(\n",
    "    disc_b.parameters(), lr=args.lr, betas=(args.b1, args.b2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate scheduler.\n",
    "class LambdaLR:\n",
    "    def __init__(self, n_epochs, offset, decay_start_epoch):\n",
    "        assert (n_epochs - decay_start_epoch) > 0, \"n_epochs must be larger than decay_start_epoch\"\n",
    "        self.n_epochs = n_epochs \n",
    "        self.offset = offset \n",
    "        self.decay_start_epoch = decay_start_epoch\n",
    "    \n",
    "    def step(self, epoch):\n",
    "        return 1.0 - max(0, epoch+self.offset - self.decay_start_epoch) / (self.n_epochs - self.decay_start_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler_g = torch.optim.lr_scheduler.LambdaLR(\n",
    "    optim_g,\n",
    "    lr_lambda=LambdaLR(args.epochs, args.start_epoch, args.decay_epoch).step\n",
    ")\n",
    "lr_scheduler_d_a = torch.optim.lr_scheduler.LambdaLR(\n",
    "    optim_d_a,\n",
    "    lr_lambda=LambdaLR(args.epochs, args.start_epoch, args.decay_epoch).step\n",
    ")\n",
    "lr_scheduler_d_b = torch.optim.lr_scheduler.LambdaLR(\n",
    "    optim_d_b,\n",
    "    lr_lambda=LambdaLR(args.epochs, args.start_epoch, args.decay_epoch).step\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to show some real and fake images. \n",
    "def sample_imgs():\n",
    "    imgs = next(iter(test_loader))\n",
    "    gen_ab.eval()\n",
    "    gen_ba.eval()\n",
    "    real_B = imgs['B'].to(device) # Photos\n",
    "    with torch.no_grad():\n",
    "        fake_A = gen_ba(real_B).detach()\n",
    "    \n",
    "    show_batch(real_B.cpu(), title=\"Photos\")\n",
    "    show_batch(fake_A.cpu(), title=\"Photos with style transfer applied\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop \n",
    "g_loss_list, d_loss_list = [], []\n",
    "\n",
    "for epoch in range(args.start_epoch, args.epochs + args.start_epoch):\n",
    "    g_epoch_loss = 0\n",
    "    d_epoch_loss = 0\n",
    "    for _, batch in tqdm(enumerate(loader)):\n",
    "        real_a = batch['A'].to(device)\n",
    "        real_b = batch['B'].to(device)\n",
    "        real_label = torch.ones((real_a.size(0), *disc_a.output_shape), dtype=torch.float).to(device)\n",
    "        fake_label = torch.zeros((real_a.size(0), *disc_a.output_shape), dtype=torch.float).to(device)\n",
    "\n",
    "        ############\n",
    "        # GENERATORS\n",
    "        ############\n",
    "        gen_ab.train()\n",
    "        gen_ba.train()\n",
    "        optim_g.zero_grad()\n",
    "        \n",
    "        # Identity loss \n",
    "        # Feeding A to gen_ba should produce A, same goes for B and gen_ab. \n",
    "        loss_id_a = loss_fn_identity(gen_ba(real_a), real_a)\n",
    "        loss_id_b = loss_fn_identity(gen_ab(real_b), real_b) \n",
    "        loss_id = (loss_id_a + loss_id_b) / 2\n",
    "\n",
    "        # GAN loss\n",
    "        fake_b = gen_ab(real_a) # Fake photo.\n",
    "        loss_gan_ab = loss_fn_gan(disc_b(fake_b), real_label) \n",
    "        fake_a = gen_ba(real_b) # Fake painting.\n",
    "        loss_gan_ba = loss_fn_gan(disc_a(fake_a), real_label)\n",
    "        loss_gan = (loss_gan_ab + loss_gan_ba) / 2\n",
    "\n",
    "        # Cycle loss \n",
    "        recov_a = gen_ba(fake_b) # Fake painting created from fake photo. \n",
    "        loss_cycle_a = loss_fn_cycle(recov_a, real_a)\n",
    "        recov_b = gen_ab(fake_a) # Fake photo created from fake painting. \n",
    "        loss_cycle_b = loss_fn_cycle(recov_b, real_b)\n",
    "        loss_cycle = (loss_cycle_a + loss_cycle_b) / 2\n",
    "\n",
    "        # Total loss \n",
    "        loss_g = loss_gan + (10 * loss_cycle) + (5 * loss_id)\n",
    "        loss_g.backward()\n",
    "        optim_g.step()\n",
    "\n",
    "        #################\n",
    "        # DISCRIMINATOR A \n",
    "        #################\n",
    "        optim_d_a.zero_grad()\n",
    "        loss_real = loss_fn_gan(disc_a(real_a), real_label) # Real paintings should be classified as real.\n",
    "        loss_fake = loss_fn_gan(disc_a(fake_a.detach()), fake_label) # Fake paintings should be classified as fake. \n",
    "        loss_d_a = (loss_real + loss_fake) / 2\n",
    "        loss_d_a.backward()\n",
    "        optim_d_a.step()\n",
    "\n",
    "        #################\n",
    "        # DISCRIMINATOR B\n",
    "        #################\n",
    "        optim_d_b.zero_grad()\n",
    "        loss_real = loss_fn_gan(disc_b(real_b), real_label)  # Real photos should be classified as real.\n",
    "        loss_fake = loss_fn_gan(disc_b(fake_b.detach()), fake_label) # Fake photos should be classified as fake. \n",
    "        loss_d_b = (loss_real + loss_fake) / 2\n",
    "        loss_d_b.backward()\n",
    "        optim_d_b.step()\n",
    "\n",
    "        # Total loss \n",
    "        loss_d = (loss_d_a + loss_d_b) / 2 \n",
    "\n",
    "        d_epoch_loss += loss_d.item()\n",
    "        g_epoch_loss += loss_g.item()\n",
    "\n",
    "    g_epoch_loss /= len(loader)\n",
    "    d_epoch_loss /= len(loader)\n",
    "    print(f\"EPOCH: {epoch}\\nGenerator loss: {g_epoch_loss:.3f}\\nDiscriminator loss: {d_epoch_loss:.3f}\\n\")\n",
    "    g_loss_list.append(g_epoch_loss)\n",
    "    d_loss_list.append(d_epoch_loss)\n",
    "\n",
    "    # Generating some images to show later. \n",
    "    if epoch % 25 == 0 or epoch == 1:\n",
    "        sample_imgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Plotting the loss and some generated images.\n",
    "plt.plot(g_loss_list, label=\"Generator loss\")\n",
    "plt.plot(d_loss_list, label=\"Discriminator loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "sample_imgs()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
